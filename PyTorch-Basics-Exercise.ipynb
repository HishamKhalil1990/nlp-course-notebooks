{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3465bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchmetrics\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from torch import nn\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f31f386",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a45b60d",
   "metadata": {},
   "source": [
    "The goal of this exercise is to implement a machine learning project using PyTorch and its ecosystem of packages.\n",
    "\n",
    "The task at hand is MNIST image classification, given a grayscale image of handwritten image, the task is to classify the image and determine which digit it represents from (0-9)\n",
    "\n",
    "The neural network that we will implement is a simple Feed Forward Neural Network (FFNN)\n",
    "\n",
    "In this exercise we will be using the following extra packages for PyTorch:\n",
    "\n",
    "1. [`torchvision`](https://pytorch.org/vision/stable/index.html): computer vision utility functions and extensions for PyTroch\n",
    "2. [`torchmetrics`](https://torchmetrics.readthedocs.io/en/stable/all-metrics.html): ready to use metrics for evaluating a machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f123d749",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "1. Some tasks are already done for you, with a link to the related documentation left for your reference\n",
    "2. Tasks that you're required to do are labeled with `TODO`\n",
    "3. Use search engines and the official documentation as much as you can to gain better insights on the topics at hand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b317f4b",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "\n",
    "1. Prepare the dataset and data loaders\n",
    "2. Explore the dataset visually\n",
    "3. Define the model architecture\n",
    "4. Prepare for training, by creating loss function, optimizer and metric function\n",
    "5. Create training scripts and train\n",
    "6. Validate the results visually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d670ed",
   "metadata": {},
   "source": [
    "## Setup Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "566bffaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f64e9a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973c6401",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3514b97",
   "metadata": {},
   "source": [
    "## Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc9ae4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a local directory to store the dataset\n",
    "data_dir = os.path.join(os.curdir, \"data\")\n",
    "Path(data_dir).mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e4f15b",
   "metadata": {},
   "source": [
    "`torchvision` is part of PyTorch ecosystem, it has utilities for computer vision models.\n",
    "\n",
    "We will first use the dataset submodule to import the *MNIST* dataset, you can find more details [here](https://pytorch.org/vision/stable/datasets.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b63e5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transform functions to apply to each image once it's downloaded\n",
    "# REFERENCE: https://pytorch.org/vision/stable/transforms.html\n",
    "transforms = torchvision.transforms.Compose(transforms=[\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Lambda(lambda x: torch.flatten(x))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9c22792e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use torchvision datasets to load both MNSIT training and testing splits\n",
    "# REFERENCE: https://pytorch.org/vision/stable/datasets.html\n",
    "train_dataset = torchvision.datasets.MNIST(data_dir,train=True,download=True,transform=transforms)\n",
    "test_dataset = torchvision.datasets.MNIST(data_dir,train=False,download=True,transform=transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90611235",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "26567850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch size\n",
    "batch_size = 36\n",
    "\n",
    "# TODO: Create dataloaders, allow shuffle and set the batch size to the defined variable\n",
    "# REFERENCE: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#preparing-your-data-for-training-with-dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc480b2c",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "04317445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Explore the dataset manually\n",
    "samples = train_dataset.data[0:6]\n",
    "labels = train_dataset.targets[0:6]\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(12, 12), nrows=3, ncols=2)\n",
    "\n",
    "axes = np.array(axes).flatten()\n",
    "\n",
    "for index, sample in enumerate(samples):\n",
    "    axes[index].imshow(sample)\n",
    "    axes[index].set_title(labels[index].item(), fontdict={\"size\": 15}, pad=15)\n",
    "    \n",
    "\n",
    "fig.subplots_adjust(hspace=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "99cf60ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(samples[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749aa12c",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cc6c0ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model class is created for you\n",
    "# TODO: Define a three layer Feed Forward Neural Network (FFNN), \n",
    "# choose the input layer and output layer dimensions as appropriate, \n",
    "# and you can personally choose the hidden dimensions\n",
    "a = samples[0].shape[0]\n",
    "b = samples[0].shape[1]\n",
    "class MNISTClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=a*b,out_features=100,bias=True)\n",
    "        self.fc2 = nn.Linear(in_features=100,out_features=50,bias=True)\n",
    "        self.fc3 = nn.Linear(in_features=50,out_features=10,bias=True)\n",
    "        self.relu = nn.functional.relu\n",
    "    # TODO: Define the fowrad function given an input image `x`\n",
    "    # REMEMBER: To pass the input to a linear layer and apply an activation function of your choice afterwards\n",
    "    # REMEMBER: The final output activation function is related to the loss function you'll use\n",
    "    def forward(self, x):\n",
    "        output = self.relu(self.fc1(x))\n",
    "        output = self.relu(self.fc2(output))\n",
    "        output = self.fc3(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1eda779f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[ 0.0336, -0.0141,  0.0207,  ...,  0.0277,  0.0083,  0.0015],\n",
      "        [ 0.0348, -0.0139,  0.0045,  ...,  0.0088, -0.0209, -0.0355],\n",
      "        [-0.0222, -0.0039, -0.0351,  ..., -0.0295,  0.0139,  0.0020],\n",
      "        ...,\n",
      "        [-0.0054, -0.0220, -0.0210,  ...,  0.0296,  0.0328,  0.0039],\n",
      "        [ 0.0120,  0.0276, -0.0151,  ...,  0.0147, -0.0351,  0.0058],\n",
      "        [ 0.0091, -0.0306,  0.0003,  ..., -0.0023, -0.0341,  0.0216]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0024, -0.0250,  0.0138,  0.0152,  0.0351, -0.0355, -0.0065, -0.0253,\n",
      "         0.0289, -0.0282,  0.0180,  0.0060, -0.0354, -0.0142,  0.0061, -0.0326,\n",
      "        -0.0207, -0.0345,  0.0272, -0.0144,  0.0076,  0.0327,  0.0002,  0.0026,\n",
      "        -0.0004, -0.0316,  0.0318,  0.0035, -0.0174, -0.0214, -0.0292, -0.0197,\n",
      "         0.0068,  0.0050, -0.0233,  0.0022,  0.0307,  0.0287, -0.0290, -0.0219,\n",
      "        -0.0186, -0.0326, -0.0185,  0.0205, -0.0063,  0.0310, -0.0199,  0.0136,\n",
      "         0.0028, -0.0145,  0.0040,  0.0250,  0.0053,  0.0229,  0.0186,  0.0143,\n",
      "         0.0115,  0.0340,  0.0233,  0.0041,  0.0295,  0.0315,  0.0267,  0.0113,\n",
      "        -0.0276,  0.0137, -0.0156,  0.0326,  0.0059, -0.0262, -0.0025, -0.0199,\n",
      "         0.0029, -0.0179, -0.0201,  0.0158,  0.0045,  0.0264,  0.0298, -0.0112,\n",
      "         0.0180, -0.0039,  0.0120, -0.0243,  0.0261,  0.0311,  0.0225, -0.0145,\n",
      "         0.0267, -0.0139, -0.0115, -0.0007, -0.0072,  0.0206, -0.0222,  0.0290,\n",
      "        -0.0334,  0.0054,  0.0088, -0.0201], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0074, -0.0847,  0.0973,  ...,  0.0941,  0.0837, -0.0675],\n",
      "        [ 0.0779,  0.0833, -0.0410,  ..., -0.0473,  0.0359,  0.0841],\n",
      "        [ 0.0432,  0.0754,  0.0582,  ..., -0.0792, -0.0119, -0.0632],\n",
      "        ...,\n",
      "        [-0.0648, -0.0651, -0.0037,  ..., -0.0837,  0.0495, -0.0057],\n",
      "        [ 0.0903,  0.0643, -0.0014,  ..., -0.0550,  0.0655,  0.0284],\n",
      "        [ 0.0911,  0.0864, -0.0106,  ...,  0.0115, -0.0670, -0.0766]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0092, -0.0610, -0.0033,  0.0765, -0.0400,  0.0434, -0.0033, -0.0649,\n",
      "         0.0463, -0.0743, -0.0738, -0.0229, -0.0256,  0.0992, -0.0680, -0.0943,\n",
      "        -0.0345, -0.0194,  0.0405,  0.0884, -0.0571,  0.0884, -0.0534, -0.0556,\n",
      "        -0.0672, -0.0276, -0.0900,  0.0913,  0.0704,  0.0466, -0.0283,  0.0842,\n",
      "         0.0423,  0.0442, -0.0639,  0.0838,  0.0519,  0.0263,  0.0120,  0.0805,\n",
      "        -0.0673, -0.0914, -0.0941, -0.0876, -0.0066,  0.0129, -0.0147, -0.0750,\n",
      "        -0.0411, -0.0108], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0999, -0.1373, -0.0251, -0.1180, -0.0842, -0.0837,  0.0270, -0.1236,\n",
      "          0.0896, -0.0872, -0.0447,  0.0394,  0.1095,  0.0464,  0.1150, -0.0239,\n",
      "          0.0595, -0.0288, -0.1015, -0.0280,  0.1022,  0.1078, -0.0077, -0.1045,\n",
      "          0.0771,  0.1300, -0.0937, -0.1352, -0.0217, -0.0045,  0.0269, -0.0072,\n",
      "         -0.0095,  0.1056, -0.0079,  0.1157,  0.0758,  0.0537,  0.1407, -0.0443,\n",
      "         -0.0509,  0.0416,  0.0505, -0.1309, -0.0050,  0.0762, -0.1155,  0.0531,\n",
      "         -0.0358,  0.0968],\n",
      "        [ 0.0476,  0.0098,  0.1151,  0.0005,  0.0154,  0.0396, -0.0836, -0.1278,\n",
      "          0.0767,  0.1294, -0.0493,  0.1207, -0.0304,  0.1120, -0.0055, -0.1209,\n",
      "          0.0301, -0.0385,  0.1227,  0.0208, -0.1404,  0.1368,  0.0126, -0.0517,\n",
      "          0.0261,  0.0248,  0.0551, -0.0674, -0.1069, -0.0154, -0.0194,  0.0157,\n",
      "         -0.0655, -0.0763,  0.0191, -0.0592,  0.0225,  0.1395,  0.0281, -0.0536,\n",
      "         -0.0116, -0.1006,  0.0881,  0.1112, -0.0724, -0.0646, -0.1197,  0.0312,\n",
      "         -0.1413,  0.1146],\n",
      "        [ 0.0460, -0.0863, -0.0151, -0.1338,  0.0917,  0.1128, -0.0244,  0.0320,\n",
      "          0.1373,  0.1078,  0.0824,  0.0363, -0.0122,  0.0847,  0.1155,  0.0984,\n",
      "          0.0544, -0.0246,  0.0356, -0.0651, -0.1372, -0.0242, -0.1190, -0.0016,\n",
      "          0.0185,  0.1097,  0.0113,  0.1015, -0.0361,  0.0780,  0.0918,  0.0829,\n",
      "          0.0147, -0.1098, -0.0811,  0.0571, -0.0754, -0.0265,  0.1189,  0.1329,\n",
      "         -0.0886, -0.0627, -0.1114,  0.0567, -0.1014,  0.0080, -0.0817,  0.0260,\n",
      "          0.1373,  0.0556],\n",
      "        [ 0.0438, -0.0914,  0.0214,  0.0913, -0.0179,  0.0984,  0.0241, -0.1354,\n",
      "         -0.1335,  0.1268, -0.0932,  0.0665,  0.0772, -0.0367, -0.0807, -0.1369,\n",
      "          0.1396, -0.0956,  0.0548, -0.1203,  0.0254,  0.1393, -0.0047, -0.0687,\n",
      "         -0.0290,  0.0483, -0.0822, -0.0014,  0.0816, -0.0349, -0.0912, -0.1197,\n",
      "          0.1168, -0.0384,  0.0417, -0.0359,  0.0968, -0.0658, -0.0096,  0.0676,\n",
      "         -0.0091, -0.0896, -0.0486,  0.0772, -0.0591, -0.0425,  0.0146,  0.0026,\n",
      "          0.0786,  0.0704],\n",
      "        [-0.0956,  0.0243,  0.0586,  0.0304, -0.0220, -0.1145, -0.0943, -0.1130,\n",
      "         -0.0800,  0.0318, -0.0029,  0.0460,  0.0204, -0.0568, -0.0256,  0.0320,\n",
      "          0.0880, -0.0104, -0.1327,  0.0779,  0.0001, -0.0977, -0.0890, -0.0299,\n",
      "         -0.0869, -0.1044, -0.0206,  0.1249, -0.1330,  0.0149, -0.0047,  0.1074,\n",
      "         -0.0044, -0.0158, -0.0978,  0.0036, -0.0586,  0.0457, -0.1282,  0.1346,\n",
      "          0.0049,  0.0916,  0.1053, -0.1369,  0.0285,  0.0632,  0.0072, -0.0039,\n",
      "         -0.1333,  0.0140],\n",
      "        [ 0.0088, -0.0025,  0.0231, -0.1332,  0.0951,  0.0661, -0.1414, -0.0469,\n",
      "          0.1078,  0.0849,  0.0458, -0.0363,  0.1173,  0.0430,  0.0485, -0.0831,\n",
      "         -0.0930,  0.0730,  0.1298,  0.0092, -0.0159,  0.0100, -0.0132,  0.0453,\n",
      "         -0.0333, -0.0019,  0.0768, -0.1151,  0.1084, -0.1130,  0.0606,  0.1109,\n",
      "          0.1020,  0.0126, -0.0217, -0.0567,  0.0168, -0.0971, -0.0557, -0.0752,\n",
      "         -0.1056,  0.0414,  0.0804, -0.0740,  0.1335,  0.0982,  0.0844,  0.0301,\n",
      "         -0.0737,  0.1211],\n",
      "        [-0.0499,  0.0663, -0.0550, -0.0170, -0.1161, -0.0100, -0.0808, -0.1058,\n",
      "         -0.0446,  0.0560, -0.0454,  0.0180,  0.1408,  0.0827,  0.0316, -0.0881,\n",
      "          0.1109,  0.1039,  0.0440, -0.0210, -0.0446,  0.1396, -0.0235,  0.0928,\n",
      "          0.1293, -0.0301,  0.1197, -0.1262, -0.0430, -0.0315, -0.0362,  0.0986,\n",
      "         -0.0418, -0.0791,  0.1302,  0.0585,  0.0049, -0.1320,  0.0613,  0.1043,\n",
      "          0.0908, -0.0969,  0.0882, -0.0300, -0.0055, -0.0923,  0.0491,  0.0256,\n",
      "          0.1100,  0.1356],\n",
      "        [ 0.0288,  0.0338,  0.1122,  0.0916,  0.0177, -0.1295, -0.1392, -0.0177,\n",
      "         -0.0883, -0.0345,  0.0188,  0.0580,  0.0851,  0.0254, -0.1215, -0.0265,\n",
      "         -0.0585,  0.1188,  0.0119,  0.1217, -0.0678,  0.0431,  0.0523,  0.0977,\n",
      "          0.1305,  0.0731, -0.0219,  0.0698, -0.0891, -0.0901, -0.1162, -0.0561,\n",
      "          0.0638,  0.0514, -0.1011,  0.1146,  0.1097,  0.0409,  0.1397, -0.0965,\n",
      "          0.1281,  0.0756,  0.1279,  0.0448, -0.0183, -0.0128, -0.0932, -0.0375,\n",
      "          0.0884, -0.0676],\n",
      "        [-0.1385,  0.1373, -0.0399,  0.1150,  0.0441,  0.0578, -0.1148,  0.0196,\n",
      "         -0.1216,  0.1158,  0.1123,  0.0945, -0.0144,  0.1017, -0.0834,  0.0988,\n",
      "         -0.0358,  0.0272, -0.1294,  0.1158,  0.0170, -0.0504, -0.0961,  0.0041,\n",
      "         -0.1128, -0.0363,  0.1096, -0.1307,  0.0488,  0.0860, -0.0701,  0.0005,\n",
      "         -0.0032, -0.1095, -0.0755, -0.0992, -0.0037,  0.0956,  0.0366, -0.0336,\n",
      "          0.0353,  0.0222, -0.0442,  0.1359, -0.0753, -0.1046,  0.1090,  0.0581,\n",
      "         -0.1372, -0.1017],\n",
      "        [-0.1098,  0.0432, -0.1272,  0.0190,  0.1119,  0.0812, -0.0499,  0.1012,\n",
      "         -0.0687,  0.1138, -0.0108,  0.1129, -0.0019,  0.0287, -0.0209,  0.1106,\n",
      "          0.0534, -0.1387, -0.0876, -0.0340, -0.0913,  0.0503,  0.0827, -0.0240,\n",
      "          0.0657, -0.0149,  0.0689, -0.0656,  0.0771,  0.1066,  0.1185, -0.0641,\n",
      "         -0.1065,  0.1042,  0.0194, -0.1184,  0.0386,  0.0417, -0.0080, -0.0314,\n",
      "          0.0430, -0.0104, -0.1184, -0.0681, -0.0732,  0.1278,  0.0217,  0.1057,\n",
      "         -0.0903, -0.1409]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0776, -0.0755,  0.0870,  0.0594, -0.0625, -0.0297,  0.0378,  0.0592,\n",
      "         0.0064, -0.0764], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "# Instanciate the model class and move it to your device \n",
    "model = MNISTClassifier()\n",
    "model = model.to(device)\n",
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00398329",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b80f219b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of epochs for training\n",
    "epochs = 15\n",
    "\n",
    "# TODO: Define the optimizer, loss criterion\n",
    "optim = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "critertion = nn.CrossEntropyLoss()\n",
    "# TODO: Define a metric function (F1 Score) to evaluate the model\n",
    "# REFERENCE: https://torchmetrics.readthedocs.io/en/stable/pages/overview.html\n",
    "# REMEMBER: To move the metric function to the appropriate device\n",
    "metric = torchmetrics.Accuracy().to(torch.device(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d349367f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dataclass object defined to store the loss and metric results of each epoch\n",
    "# REFERENCE: https://realpython.com/python-data-classes/\n",
    "@dataclass\n",
    "class Epoch:\n",
    "    epoch: int\n",
    "    training_loss: float\n",
    "    validation_loss: float\n",
    "    training_acc: float\n",
    "    validation_acc: float\n",
    "        \n",
    "    \n",
    "    def log(self) -> None:\n",
    "        print(f\"Epoch {self.epoch + 1}: Training Loss: {self.training_loss}\\tValidation Loss: {self.validation_loss} || Training F1: {self.training_acc}\\tValidation F1: {self.validation_acc}\\n----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4063a0f",
   "metadata": {},
   "source": [
    "Instructions for training script ***for each epoch***:\n",
    "\n",
    "1. Set the initial epoch train and validation loss and metric to zero and reset the metric function\n",
    "2. Set the model to training mode \n",
    "3. Load all batches in *train* dataloader\n",
    "4. For each batch, unpack the inputs and target, move them to the correct device and pass them to the model to get predictions\n",
    "5. Calculate loss and metric values for the prediction\n",
    "6. Backpropagate the loss\n",
    "7. Accumulate the epoch train loss and metric\n",
    "8. Repeat the previous steps with appropriate changes to evaluate the model on the *test* data \n",
    "9. Store the epoch results in a history list\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "69ac3983",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [79]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m loss \u001b[38;5;241m=\u001b[39m critertion(inputs, target)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m#f1 = \u001b[39;00m\n\u001b[0;32m     31\u001b[0m \n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# TODO: Backward propagataion\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m optim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Accumulate train loss\u001b[39;00m\n",
      "File \u001b[1;32mc:\\python_projects\\nlp\\nlp-course-notebooks\\venv\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\python_projects\\nlp\\nlp-course-notebooks\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "#history: list[Epoch] = []\n",
    "history = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # TODO: Define epoch train and test: loss and metrics\n",
    "    epoch_train_loss = 0\n",
    "    epoch_train_f1 = 0\n",
    "    epoch_val_loss = 0\n",
    "    epoch_val_f1 = 0\n",
    "    # TODO: Make sure to reset the metric function\n",
    "    #metric.reset()\n",
    "    # TODO: Set the model to training mode\n",
    "    model.train()\n",
    "    print(model.training)\n",
    "    # Iterate train batches\n",
    "    for batch in train_loader:\n",
    "        \n",
    "        # REMEMBER: you need to reset the optimizer in order to avoid incorrect accumulation of gradientrs \n",
    "        optim.zero_grad()\n",
    "        \n",
    "        # TODO: Unpack the batch and move it to the correct device\n",
    "        inputs, target = batch\n",
    "        inputs, target = inputs.to(device),target.to(device)\n",
    "\n",
    "        # TODO: get prediction from model\n",
    "        predictions = model(inputs)\n",
    "        \n",
    "        # TODO: Calculate loss and metric\n",
    "        loss = critertion(inputs, target)\n",
    "        #f1 = \n",
    "        \n",
    "        # TODO: Backward propagataion\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        # Accumulate train loss\n",
    "        epoch_train_loss += loss.item()\n",
    "    \n",
    "    # Calculate epoch training metric\n",
    "    epoch_train_f1 = round(metric.compute().item(), 3)\n",
    "\n",
    "    \n",
    "    # TODO: set the model to test mode\n",
    "    model.eval()\n",
    "    # Reset the metric function\n",
    "    #metric.reset()\n",
    "    # Make sure PyTorch will run inference without tracking gradients for enhancing performance\n",
    "    with torch.no_grad():\n",
    "        # TODO: Load batches from `test_loader`\n",
    "        for  batch in test_loader:\n",
    "            \n",
    "            # TODO: Unpack the batch and move it to the correct device\n",
    "            inputs, target = batch\n",
    "            inputs, target = inputs.to(device),target.to(device)\n",
    "\n",
    "            # TODO: get prediction from model\n",
    "            predictions = model(inputs)\n",
    "            \n",
    "            # TODO: Calculate loss and metric values\n",
    "            loss = critertion(inputs, target)\n",
    "            #f1 = \n",
    "            \n",
    "            # TODO: Accumulate validation loss\n",
    "            epoch_val_loss += loss.item()\n",
    "            \n",
    "        # TODO: Calculate epoch validation metric\n",
    "        epoch_val_f1 = round(metric.compute().item(), 3)\n",
    "      \n",
    "\n",
    "    # Calculate epoch training loss\n",
    "    epoch_train_loss = round(epoch_train_loss / len(train_loader), 3)\n",
    "    # TODO: Calculate epoch validation loss\n",
    "    epoch_val_loss = round(epoch_val_loss / len(test_loader), 3)\n",
    "    \n",
    "    # TODO: Create `Epoch` instance with the results\n",
    "    epoch_result = Epoch(epoch=epoch, \n",
    "                         training_loss=epoch_train_loss, \n",
    "                         validation_loss=epoch_val_loss,\n",
    "                         training_acc=epoch_train_f1,\n",
    "                         validation_acc=epoch_val_f1,\n",
    "                        )\n",
    "    \n",
    "    # Add to history list\n",
    "    history.append(epoch_result)\n",
    "    # Log epoch output\n",
    "    epoch_result.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d26569b",
   "metadata": {},
   "source": [
    "# Visual Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b187bf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample = next(iter(test_loader))\n",
    "inputs, labels = sample\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(20, 20), ncols=6, nrows=6)\n",
    "\n",
    "axes = np.array(axes).flatten()\n",
    "\n",
    "model.eval()\n",
    "for index in range(len(inputs)):\n",
    "    im = inputs[index]\n",
    "    label = labels[index].item()\n",
    "    \n",
    "    prediction = torch.softmax(model(im.to(device)), dim=-1)\n",
    "    prediction = torch.argmax(prediction).item()\n",
    "    \n",
    "    color = \"green\" if prediction == label else \"red\"\n",
    "    axes[index].set_title(f\"Predicted: {prediction}  Actual: {label}\", color=color)\n",
    "    \n",
    " \n",
    "    axes[index].imshow(im.reshape((28, 28)))\n",
    "    \n",
    "    \n",
    "fig.suptitle(\"Sample Predictions\", y=0.92, fontsize=15)\n",
    "fig.subplots_adjust(hspace=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124e7393",
   "metadata": {},
   "source": [
    "# Extras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04671c3",
   "metadata": {},
   "source": [
    "1. Train the model on the Fashion MNIST dataset\n",
    "2. Create a deeper neural network\n",
    "3. Try a different metric function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a73623a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "7ec8ca894ee27eb0429edfd9efb55f71ec59f0b9714a70caee63d0a988928375"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
