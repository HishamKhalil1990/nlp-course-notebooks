{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3465bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchmetrics\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from torch import nn\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f31f386",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a45b60d",
   "metadata": {},
   "source": [
    "The goal of this exercise is to implement a machine learning project using PyTorch and its ecosystem of packages.\n",
    "\n",
    "The task at hand is MNIST image classification, given a grayscale image of handwritten image, the task is to classify the image and determine which digit it represents from (0-9)\n",
    "\n",
    "The neural network that we will implement is a simple Feed Forward Neural Network (FFNN)\n",
    "\n",
    "In this exercise we will be using the following extra packages for PyTorch:\n",
    "\n",
    "1. [`torchvision`](https://pytorch.org/vision/stable/index.html): computer vision utility functions and extensions for PyTroch\n",
    "2. [`torchmetrics`](https://torchmetrics.readthedocs.io/en/stable/all-metrics.html): ready to use metrics for evaluating a machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f123d749",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "1. Some tasks are already done for you, with a link to the related documentation left for your reference\n",
    "2. Tasks that you're required to do are labeled with `TODO`\n",
    "3. Use search engines and the official documentation as much as you can to gain better insights on the topics at hand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b317f4b",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "\n",
    "1. Prepare the dataset and data loaders\n",
    "2. Explore the dataset visually\n",
    "3. Define the model architecture\n",
    "4. Prepare for training, by creating loss function, optimizer and metric function\n",
    "5. Create training scripts and train\n",
    "6. Validate the results visually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d670ed",
   "metadata": {},
   "source": [
    "## Setup Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566bffaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64e9a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973c6401",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3514b97",
   "metadata": {},
   "source": [
    "## Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc9ae4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a local directory to store the dataset\n",
    "data_dir = os.path.join(os.curdir, \"data\")\n",
    "Path(data_dir).mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e4f15b",
   "metadata": {},
   "source": [
    "`torchvision` is part of PyTorch ecosystem, it has utilities for computer vision models.\n",
    "\n",
    "We will first use the dataset submodule to import the *MNIST* dataset, you can find more details [here](https://pytorch.org/vision/stable/datasets.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b63e5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transform functions to apply to each image once it's downloaded\n",
    "# REFERENCE: https://pytorch.org/vision/stable/transforms.html\n",
    "transforms = torchvision.transforms.Compose(transforms=[\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Lambda(lambda x: torch.flatten(x))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c22792e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use torchvision datasets to load both MNSIT training and testing splits\n",
    "# REFERENCE: https://pytorch.org/vision/stable/datasets.html\n",
    "train_dataset = torchvision.datasets.MNIST(data_dir,train=True,download=True,transform=transforms)\n",
    "test_dataset = torchvision.datasets.MNIST(data_dir,train=False,download=True,transform=transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90611235",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26567850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch size\n",
    "batch_size = 36\n",
    "\n",
    "# TODO: Create dataloaders, allow shuffle and set the batch size to the defined variable\n",
    "# REFERENCE: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#preparing-your-data-for-training-with-dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc480b2c",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04317445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the dataset manually\n",
    "samples = train_dataset.data[0:6]\n",
    "labels = train_dataset.targets[0:6]\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(12, 12), nrows=3, ncols=2)\n",
    "\n",
    "axes = np.array(axes).flatten()\n",
    "\n",
    "for index, sample in enumerate(samples):\n",
    "    axes[index].imshow(sample)\n",
    "    axes[index].set_title(labels[index].item(), fontdict={\"size\": 15}, pad=15)\n",
    "    \n",
    "\n",
    "fig.subplots_adjust(hspace=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cf60ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samples[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749aa12c",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6c0ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model class is created for you\n",
    "# TODO: Define a three layer Feed Forward Neural Network (FFNN), \n",
    "# choose the input layer and output layer dimensions as appropriate, \n",
    "# and you can personally choose the hidden dimensions\n",
    "a = samples[0].shape[0]\n",
    "b = samples[0].shape[1]\n",
    "class MNISTClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=a*b,out_features=100,bias=True)\n",
    "        self.fc2 = nn.Linear(in_features=100,out_features=50,bias=True)\n",
    "        self.fc3 = nn.Linear(in_features=50,out_features=10,bias=True)\n",
    "    \n",
    "    # TODO: Define the fowrad function given an input image `x`\n",
    "    # REMEMBER: To pass the input to a linear layer and apply an activation function of your choice afterwards\n",
    "    # REMEMBER: The final output activation function is related to the loss function you'll use\n",
    "    def forward(self, x):\n",
    "        output = self.fc1(x)\n",
    "        output = self.fc2(output)\n",
    "        output = self.fc3(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eda779f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate the model class and move it to your device \n",
    "model = MNISTClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00398329",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80f219b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of epochs for training\n",
    "epochs = 15\n",
    "\n",
    "# TODO: Define the optimizer, loss criterion\n",
    "optim = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "critertion = nn.CrossEntropyLoss()\n",
    "# TODO: Define a metric function (F1 Score) to evaluate the model\n",
    "# REFERENCE: https://torchmetrics.readthedocs.io/en/stable/pages/overview.html\n",
    "# REMEMBER: To move the metric function to the appropriate device\n",
    "metric = torchmetrics.Accuracy().to(torch.device(device, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d349367f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dataclass object defined to store the loss and metric results of each epoch\n",
    "# REFERENCE: https://realpython.com/python-data-classes/\n",
    "@dataclass\n",
    "class Epoch:\n",
    "    epoch: int\n",
    "    training_loss: float\n",
    "    validation_loss: float\n",
    "    training_acc: float\n",
    "    validation_acc: float\n",
    "        \n",
    "    \n",
    "    def log(self) -> None:\n",
    "        print(f\"Epoch {self.epoch + 1}: Training Loss: {self.training_loss}\\tValidation Loss: {self.validation_loss} || Training F1: {self.training_acc}\\tValidation F1: {self.validation_acc}\\n----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4063a0f",
   "metadata": {},
   "source": [
    "Instructions for training script ***for each epoch***:\n",
    "\n",
    "1. Set the initial epoch train and validation loss and metric to zero and reset the metric function\n",
    "2. Set the model to training mode \n",
    "3. Load all batches in *train* dataloader\n",
    "4. For each batch, unpack the inputs and target, move them to the correct device and pass them to the model to get predictions\n",
    "5. Calculate loss and metric values for the prediction\n",
    "6. Backpropagate the loss\n",
    "7. Accumulate the epoch train loss and metric\n",
    "8. Repeat the previous steps with appropriate changes to evaluate the model on the *test* data \n",
    "9. Store the epoch results in a history list\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ac3983",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#history: list[Epoch] = []\n",
    "history = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # TODO: Define epoch train and test: loss and metrics\n",
    "    epoch_train_loss = 0\n",
    "    epoch_train_f1 = 0\n",
    "    epoch_val_loss = 0\n",
    "    epoch_val_f1 = 0\n",
    "    # TODO: Make sure to reset the metric function\n",
    "    #metric.reset()\n",
    "    # TODO: Set the model to training mode\n",
    "    model.train()\n",
    "    # Iterate train batches\n",
    "    for batch in train_loader:\n",
    "        \n",
    "        # REMEMBER: you need to reset the optimizer in order to avoid incorrect accumulation of gradientrs \n",
    "        optim.zero_grad()\n",
    "        \n",
    "        # TODO: Unpack the batch and move it to the correct device\n",
    "        inputs, target = batch\n",
    "        inputs, target = inputs.to(device),target.to(device)\n",
    "\n",
    "        # TODO: get prediction from model\n",
    "        predictions = model(inputs)\n",
    "        \n",
    "        # TODO: Calculate loss and metric\n",
    "        loss = critertion(inputs, target)\n",
    "        print(loss)\n",
    "        #f1 = \n",
    "        \n",
    "        # TODO: Backward propagataion\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        # Accumulate train loss\n",
    "        epoch_train_loss += loss.item()\n",
    "    \n",
    "    # Calculate epoch training metric\n",
    "    #epoch_train_f1 = round(metric.compute().item(), 3)\n",
    "\n",
    "    \n",
    "    # TODO: set the model to test mode\n",
    "    model.eval()\n",
    "    # Reset the metric function\n",
    "    #metric.reset()\n",
    "    # Make sure PyTorch will run inference without tracking gradients for enhancing performance\n",
    "    with torch.no_grad():\n",
    "        # TODO: Load batches from `test_loader`\n",
    "        for  batch in test_loader:\n",
    "            \n",
    "            # TODO: Unpack the batch and move it to the correct device\n",
    "            inputs, target = batch\n",
    "            inputs, target = inputs.to(device),target.to(device)\n",
    "\n",
    "            # TODO: get prediction from model\n",
    "            predictions = model(inputs)\n",
    "            \n",
    "            # TODO: Calculate loss and metric values\n",
    "            loss = critertion(inputs, target)\n",
    "            #f1 = \n",
    "            \n",
    "            # TODO: Accumulate validation loss\n",
    "            epoch_val_loss += loss.item()\n",
    "            \n",
    "        # TODO: Calculate epoch validation metric\n",
    "        #epoch_val_f1 = \n",
    "      \n",
    "\n",
    "    # Calculate epoch training loss\n",
    "    epoch_train_loss = round(epoch_train_loss / len(train_loader), 3)\n",
    "    # TODO: Calculate epoch validation loss\n",
    "    epoch_val_loss = round(epoch_val_loss / len(test_loader), 3)\n",
    "    \n",
    "    # TODO: Create `Epoch` instance with the results\n",
    "    epoch_result = Epoch(epoch=epoch, \n",
    "                         training_loss=epoch_train_loss, \n",
    "                         validation_loss=epoch_val_loss,\n",
    "                         training_acc=0,\n",
    "                         validation_acc=0,\n",
    "                        )\n",
    "    \n",
    "    # Add to history list\n",
    "    history.append(epoch_result)\n",
    "    # Log epoch output\n",
    "    epoch_result.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d26569b",
   "metadata": {},
   "source": [
    "# Visual Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b187bf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample = next(iter(test_loader))\n",
    "inputs, labels = sample\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(20, 20), ncols=6, nrows=6)\n",
    "\n",
    "axes = np.array(axes).flatten()\n",
    "\n",
    "model.eval()\n",
    "for index in range(len(inputs)):\n",
    "    im = inputs[index]\n",
    "    label = labels[index].item()\n",
    "    \n",
    "    prediction = torch.softmax(model(im.to(device)), dim=-1)\n",
    "    prediction = torch.argmax(prediction).item()\n",
    "    \n",
    "    color = \"green\" if prediction == label else \"red\"\n",
    "    axes[index].set_title(f\"Predicted: {prediction}  Actual: {label}\", color=color)\n",
    "    \n",
    " \n",
    "    axes[index].imshow(im.reshape((28, 28)))\n",
    "    \n",
    "    \n",
    "fig.suptitle(\"Sample Predictions\", y=0.92, fontsize=15)\n",
    "fig.subplots_adjust(hspace=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124e7393",
   "metadata": {},
   "source": [
    "# Extras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04671c3",
   "metadata": {},
   "source": [
    "1. Train the model on the Fashion MNIST dataset\n",
    "2. Create a deeper neural network\n",
    "3. Try a different metric function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a73623a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "7ec8ca894ee27eb0429edfd9efb55f71ec59f0b9714a70caee63d0a988928375"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
