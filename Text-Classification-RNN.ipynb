{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ea40c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffdaa66",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f2edafab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(os.curdir, \"data\")\n",
    "vocab_path = os.path.join(data_dir, \"word-level-vocab.json\")\n",
    "dataset_path = \"https://shai-nlp-course.netlify.app/clean-tweets.tsv\"\n",
    "\n",
    "with open(vocab_path, \"rt\") as f:\n",
    "    vocab = json.load(f)\n",
    "    \n",
    "dataset = pd.read_csv(filepath_or_buffer=dataset_path, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "975f8462",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = dataset[\"clean_text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "189bb3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size = 10998\n"
     ]
    }
   ],
   "source": [
    "OOV_TOKEN = \"[OOV]\"\n",
    "PAD_TOKEN = \"[PAD]\"\n",
    "\n",
    "OOV_INDEX = vocab.get(OOV_TOKEN)\n",
    "\n",
    "print(f\"Vocab Size = {len(vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e79f4714",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_tweets = [[vocab.get(token) for token in tweet.split(\" \") if token in vocab] for tweet in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b066def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32002847",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b1fdd6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(tweet) for tweet in tokenized_tweets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ef7ba7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = nn.utils.rnn.pad_sequence([torch.tensor(tweet) for tweet in tokenized_tweets], \n",
    "                          batch_first=True, \n",
    "                          padding_value=vocab.get(PAD_TOKEN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "baa3eada",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor(pd.get_dummies(dataset[\"Sentiment\"]).to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c705a3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4000, 72]), torch.Size([4000, 3]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "79883725",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "66a3462c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.utils.data.TensorDataset(X, y)\n",
    "dataloader = torch.utils.data.DataLoader(dataset=data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7facdb1",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "736f7fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 72])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:16][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3b79bc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentAnalyzer(nn.Module):\n",
    "    def __init__(self, vocab_size: int, embedding_dim: int, latent_dim: int, padding_idx: int = 0):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.padding_idx = padding_idx\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embeddings=self.vocab_size, \n",
    "                                      embedding_dim=self.embedding_dim, \n",
    "                                      padding_idx=self.padding_idx, \n",
    "                                      max_norm=1.0)\n",
    "        \n",
    "        self.rnn = nn.RNN(input_size=self.embedding_dim, hidden_size=self.latent_dim, \n",
    "                          batch_first=True)\n",
    "        \n",
    "        \n",
    "        self.fc = nn.Linear(in_features=self.latent_dim, out_features=3)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x = (batch_size, sequence_length) \n",
    "        \n",
    "        embeddings = self.embedding(x)\n",
    "        \n",
    "        # embeddings = (batch_size, sequence_length, embedding_dim)\n",
    "        \n",
    "        hidden_states, output = self.rnn(embeddings)\n",
    "        \n",
    "        # Continue from here\n",
    "        output = output[-1,:,:]\n",
    "        output = self.fc(output)\n",
    "        \n",
    "        return output\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "52980f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 300\n",
    "LATENT_DIM = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "46c9ccc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentAnalyzer(vocab_size=len(vocab), embedding_dim=EMBEDDING_DIM, latent_dim=LATENT_DIM).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7da08cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data[0:BATCH_SIZE][0].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ae980d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "315770b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2afce48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
