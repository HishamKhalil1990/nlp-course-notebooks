{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9f3aeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421257f1",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8bcc29f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['word_tokenizer.pkl',\n",
       " 'clean-tweets.tsv',\n",
       " 'arsentd-lev',\n",
       " 'arsentd-lev.zip',\n",
       " 'MNIST']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = os.path.join(os.curdir, \"data\")\n",
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab171d7c",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0b479f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Country</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_Expression</th>\n",
       "      <th>Sentiment_Target</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"أنا أؤمن بأن الانسان ينطفئ جماله عند ابتعاد م...</td>\n",
       "      <td>lebanon</td>\n",
       "      <td>personal</td>\n",
       "      <td>negative</td>\n",
       "      <td>implicit</td>\n",
       "      <td>بريق العيون</td>\n",
       "      <td>23</td>\n",
       "      <td>132</td>\n",
       "      <td>أؤمن بأن الانسان ينطفئ جماله ابتعاد يحب بريق ا...</td>\n",
       "      <td>اؤم بأن انس طفئ جمل بعد يحب برق عين خفي صبح ذب...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>من الذاكره... @3FInQe . عندما اعتقد كريستيانو ...</td>\n",
       "      <td>jordan</td>\n",
       "      <td>sports</td>\n",
       "      <td>positive</td>\n",
       "      <td>explicit</td>\n",
       "      <td>افضل لاعب في العالم</td>\n",
       "      <td>23</td>\n",
       "      <td>141</td>\n",
       "      <td>الذاكره عندما اعتقد كريستيانو انه افضل لاعب ال...</td>\n",
       "      <td>ذكر عند عقد كريستيانو انه فضل لعب علم ككا يسي ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>لا نخلو من ضغوطات الحياة. فنحن نعيش على أرض أع...</td>\n",
       "      <td>palestine</td>\n",
       "      <td>personal</td>\n",
       "      <td>neutral</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>24</td>\n",
       "      <td>133</td>\n",
       "      <td>نخلو ضغوطات الحياة فنحن نعيش أرض أعدت للبلاء و...</td>\n",
       "      <td>خلو ضغط حية فنح نعش ارض اعد بلء ولم سلم بيء وك...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#مصطلحات_لبنانيه_حيرت_البشريه بتوصل عالبيت ، ب...</td>\n",
       "      <td>lebanon</td>\n",
       "      <td>personal</td>\n",
       "      <td>negative</td>\n",
       "      <td>explicit</td>\n",
       "      <td>مصطلحات_لبنانيه</td>\n",
       "      <td>23</td>\n",
       "      <td>135</td>\n",
       "      <td>بتوصل عالبيت بنط بقلك جيت بتقعد لتتحدث معو بقل...</td>\n",
       "      <td>وصل علب بنط بقل جيت قعد حدث معو بقل شو تقم تمش...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>نصمت !! لتسير حياتنا على مً يرام فالناّس لم تع...</td>\n",
       "      <td>palestine</td>\n",
       "      <td>personal</td>\n",
       "      <td>negative</td>\n",
       "      <td>explicit</td>\n",
       "      <td>س لم تعد كما ك</td>\n",
       "      <td>16</td>\n",
       "      <td>67</td>\n",
       "      <td>نصمت لتسير حياتنا يرام فالناس تعد كآنت نقيه</td>\n",
       "      <td>نصم تسر حيت يرم لنس تعد كآن نقه</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet    Country     Topic  \\\n",
       "0  \"أنا أؤمن بأن الانسان ينطفئ جماله عند ابتعاد م...    lebanon  personal   \n",
       "1  من الذاكره... @3FInQe . عندما اعتقد كريستيانو ...     jordan    sports   \n",
       "2  لا نخلو من ضغوطات الحياة. فنحن نعيش على أرض أع...  palestine  personal   \n",
       "3  #مصطلحات_لبنانيه_حيرت_البشريه بتوصل عالبيت ، ب...    lebanon  personal   \n",
       "4  نصمت !! لتسير حياتنا على مً يرام فالناّس لم تع...  palestine  personal   \n",
       "\n",
       "  Sentiment Sentiment_Expression     Sentiment_Target  word_count  char_count  \\\n",
       "0  negative             implicit          بريق العيون          23         132   \n",
       "1  positive             explicit  افضل لاعب في العالم          23         141   \n",
       "2   neutral                 none                 none          24         133   \n",
       "3  negative             explicit      مصطلحات_لبنانيه          23         135   \n",
       "4  negative             explicit       س لم تعد كما ك          16          67   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  أؤمن بأن الانسان ينطفئ جماله ابتعاد يحب بريق ا...   \n",
       "1  الذاكره عندما اعتقد كريستيانو انه افضل لاعب ال...   \n",
       "2  نخلو ضغوطات الحياة فنحن نعيش أرض أعدت للبلاء و...   \n",
       "3  بتوصل عالبيت بنط بقلك جيت بتقعد لتتحدث معو بقل...   \n",
       "4        نصمت لتسير حياتنا يرام فالناس تعد كآنت نقيه   \n",
       "\n",
       "                                       clean_stemmed  \n",
       "0  اؤم بأن انس طفئ جمل بعد يحب برق عين خفي صبح ذب...  \n",
       "1  ذكر عند عقد كريستيانو انه فضل لعب علم ككا يسي ...  \n",
       "2  خلو ضغط حية فنح نعش ارض اعد بلء ولم سلم بيء وك...  \n",
       "3  وصل علب بنط بقل جيت قعد حدث معو بقل شو تقم تمش...  \n",
       "4                    نصم تسر حيت يرم لنس تعد كآن نقه  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filepath = os.path.join(data_dir, \"clean-tweets.tsv\")\n",
    "raw = pd.read_csv(filepath_or_buffer=data_filepath, sep=\"\\t\")\n",
    "\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92b10e9",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe0fbc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a generic Tokenizer class\n",
    "# Different tokenizers will inherit from this class\n",
    "class Tokenizer:\n",
    "    def __init__(self, corpus: list[str]):\n",
    "        self.vocab = self._create_vocab(corpus=corpus)\n",
    "        \n",
    "    def _create_vocab(self, corpus: list[str]) -> dict[str, int]:\n",
    "        ...\n",
    "    \n",
    "    def _tokenize_document(self, document: str) -> list[int]:\n",
    "        ...\n",
    "    \n",
    "    def tokenize(self, documents: list[str]) -> list[list[int]]:\n",
    "        return [self._tokenize_document(document) for document in documents]\n",
    "\n",
    "class WordLevelTokenizer(Tokenizer):\n",
    "    def __init__(self, corpus: list[str]):\n",
    "        super().__init__(corpus=corpus)\n",
    "        \n",
    "    def _create_vocab(self, corpus: list[str]) -> dict[str, int]:\n",
    "        all_word_tokens = set([token for sample in corpus for token in sample.split(\" \")])\n",
    "        vocab = {token: index for index, token in enumerate(word_level_tokens, start=1)} \n",
    "        return vocab\n",
    "    \n",
    "    def _tokenize_document(self, document: str) -> list[int]:\n",
    "        return [self.vocab.get(token, -1) for token in document.split(\" \")]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cb47327",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_path = os.path.join(data_dir, \"word-tokenizer.pkl\")\n",
    "\n",
    "with open(tokenizer_path, \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fc4007",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2c973d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = raw[\"clean_stemmed\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5bd3de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_tweets = tokenizer.tokenize(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47171104",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = len(tokenized_tweets)\n",
    "vocab_size = len(tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49062956",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c662e8",
   "metadata": {},
   "source": [
    "## One Hot (BoW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba11d4d4",
   "metadata": {},
   "source": [
    "Desired shape is: `[num_samples, vocab_size]`\n",
    "\n",
    "1. Define matrix of the desired shape, filled with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "505d7e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_onehot = np.zeros((num_samples, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c36add2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, sample in enumerate(tokenized_tweets):\n",
    "    for token in sample:\n",
    "        bow_onehot[index, token] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600dcc13",
   "metadata": {},
   "source": [
    "## Count Encoding (BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f003c498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement Count Encoding\n",
    "bow_count = np.zeros(()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ce745a",
   "metadata": {},
   "source": [
    "## One Hot Encoding (Sequential)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ec6205",
   "metadata": {},
   "source": [
    "Desired Shape: `[num_samples, max_length, vocab_size]`\n",
    "\n",
    "> Padding is required\n",
    "\n",
    "But first let's implement, creating a matrix for each document with shape: `[len_document, vocab_size]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8957f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_seq = []\n",
    "for sample in tokenized_tweets:\n",
    "    doc_matrix = np.zeros((len(sample), vocab_size))\n",
    "    for token_index, token in enumerate(sample):\n",
    "        doc_matrix[token_index, token] = 1\n",
    "    ohe_seq.append(doc_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957d6c01",
   "metadata": {},
   "source": [
    "### Determine Max Length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fcd57d",
   "metadata": {},
   "source": [
    "In order to create a matrix of fixed dimensions, we need to set a fixed length for all sentences aliased as `max_length`\n",
    "\n",
    "There are two approaches to determine this value:\n",
    "1. Find the document with the maximum length\n",
    "2. Find the *nth* percentile (95th, 98th, ..etc) for the docuemnts' lengths\n",
    "\n",
    "The second approach is recommended, since it takes into account outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15c4f4e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "docs_lengths = [len(document) for document in tokenized_tweets]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 12))\n",
    "\n",
    "\n",
    "sns.boxplot(y=docs_lengths, ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4d46011",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = int(np.percentile(a=docs_lengths, q=98))\n",
    "pad_idx = tokenizer.vocab.get('[PAD]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4254b218",
   "metadata": {},
   "source": [
    "One approach to creating padded sequences is:\n",
    "1. Create the output matrix as all padding\n",
    "2. Limit documents with length greater than `max_length`\n",
    "3. Replace the padding vectors with real token vectors whenever found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c809d206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "ohe_seq = np.zeros((num_samples, max_length, vocab_size))\n",
    "ohe_seq[:, :, pad_idx] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fb0ab19",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc_index, document in enumerate(tokenized_tweets):\n",
    "    \n",
    "    # Step 2\n",
    "    document = document if len(document) <= max_length else document[0:max_length]\n",
    "    \n",
    "    # Step 3\n",
    "    for token_order, token in enumerate(document):\n",
    "        ohe_seq[doc_index, token_order, pad_idx] = 0\n",
    "        ohe_seq[doc_index, token_order, token] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1dc66ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 21, 7755)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_seq.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ff6389",
   "metadata": {},
   "source": [
    "## One Hot Encoding Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d469dd1",
   "metadata": {},
   "source": [
    "Perform one hot encoding with a third party library\n",
    "\n",
    "Suggestions: \n",
    "\n",
    "- [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)\n",
    "\n",
    "- [torchtext](https://pytorch.org/text/stable/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcdfda1",
   "metadata": {},
   "source": [
    "## TF-IDF (Exercise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0111b08a",
   "metadata": {},
   "source": [
    "Steps:\n",
    "1. For the corpus calculate document frequency for each token (DF)\n",
    "2. For the corpus calculate inverse of document frequency for each token (IDF)\n",
    "3. For each document calculate term frequency (TF) for each token\n",
    "4. Calculate TF-IDF\n",
    "\n",
    "Desired output shape: `[num_samples, vocab_size]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ae66a9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = np.zeros(len(tokenizer.vocab))\n",
    "\n",
    "counter = Counter()\n",
    "for tweet in tweets:\n",
    "    unique_tokens = set([word for word in tweet.split(\" \")])\n",
    "    counter.update(unique_tokens)\n",
    "    \n",
    "for token, index in tokenizer.vocab.items():\n",
    "    df[index] = counter.get(token, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "152fc52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = np.log(len(tweets) / df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a6f7470f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = np.zeros((len(tweets), len(tokenizer.vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6786d521",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = np.zeros((len(tweets), len(tokenizer.vocab)))\n",
    "documents_length = np.array([len(tweet.split(\" \")) for tweet in tweets])\n",
    "\n",
    "for index, tweet in enumerate(tweets):\n",
    "    for token in tweet.split(\" \"):\n",
    "        tf[index, tokenizer.vocab.get(token)] += 1\n",
    "\n",
    "tf = tf / documents_length[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "00729b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b605b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
